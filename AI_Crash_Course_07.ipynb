{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-Crash_Course_07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPL3aA+DuPLdTCK5pGTddSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinHern/AI-Crash-Course/blob/main/AI_Crash_Course_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3L6p00dGZs4"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "[Presentation: AI Crash Course 07](https://view.genial.ly/61a033a3d9c41f0da944cd11/presentation-ai-crashcourse07)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2hOe4K0Hmut"
      },
      "source": [
        "## 0) Preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEWUjG0IIJkk"
      },
      "source": [
        "# ----- Libraries ----- #\n",
        "\n",
        "# For graph plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.math import confusion_matrix\n",
        "\n",
        "# For dataset manipulation\n",
        "import numpy as np\n",
        "\n",
        "# For visualizing more complex graphs\n",
        "import seaborn as sns\n",
        "\n",
        "# Neural networks\n",
        "import tensorflow as tf\n",
        "\n",
        "# Global constant for training acceleration\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Lets load an extension that helps us to visualize the performance of our model\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okEGIBRLLg1z"
      },
      "source": [
        "## 1) Dataset Preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncn_CmxWYqL1"
      },
      "source": [
        "# Lets use an already available dataset\n",
        "from tensorflow.keras import datasets\n",
        "\n",
        "# Lets try to classify numbers between 0 and 9\n",
        "(train_images, __), (test_images, __) = datasets.mnist.load_data()\n",
        "\n",
        "# A good practice when dealing with images: Normalize images from 0 to 1 or from -1 to 1.\n",
        "# We do not want our neural net to have big weights â†’ one slight change and the outcome may be completely different!\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I53Qd8obhFg"
      },
      "source": [
        "# Lets visualize a few samples\n",
        "print(train_images[0].shape)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTY6_xH2-2eh"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTftL6mtyGcH"
      },
      "source": [
        "## 2) Encoder Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr7_9kyOyLBt"
      },
      "source": [
        "class Encoder(tf.keras.models.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.inputs = tf.keras.layers.InputLayer(input_shape=(28,28,1))\n",
        "\n",
        "    ''' Actual Model Architecture '''\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu')\n",
        "    self.batch1 = tf.keras.layers.BatchNormalization()\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu')\n",
        "    self.batch2 = tf.keras.layers.BatchNormalization()\n",
        "    self.conv3 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu')\n",
        "    self.batch3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    ''' Latent Space '''\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.latent_space = tf.keras.layers.Dense(units=latent_dim, activation='relu')\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    \n",
        "    x = self.inputs(x)\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.batch1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.batch2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.batch3(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    outputs = self.latent_space(x)\n",
        "    \n",
        "    return outputs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ruvQ86a00Kb"
      },
      "source": [
        "dummy_encoder = Encoder(latent_dim=128)\n",
        "dummy_result = dummy_encoder(np.reshape(train_images[0:10], newshape=(10, 28, 28, 1)))\n",
        "dummy_result.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYsVjAGlyIq6"
      },
      "source": [
        "## 3) Decoder Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dIbrdLw1kbe"
      },
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.inputs = tf.keras.layers.InputLayer(input_shape=(latent_dim))\n",
        "    self.reshape = tf.keras.layers.Reshape(target_shape=(1 , 1, latent_dim))\n",
        "\n",
        "    ''' Actual Model Architecture '''\n",
        "    self.ct1 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(2,2), strides=(2,2), activation='relu', padding='same')\n",
        "    self.batch1 = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    self.ct2 = tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=(2,2), strides=(2,2), activation='relu', padding='same')\n",
        "    self.batch2 = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    self.ct3 = tf.keras.layers.Conv2DTranspose(filters=8, kernel_size=(4,4), strides=(7,7), activation='relu', padding='same')\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.inputs(x)\n",
        "    x = self.reshape(x)\n",
        "\n",
        "    x = self.ct1(x)\n",
        "    x = self.batch1(x)\n",
        "    x = self.ct2(x)\n",
        "    x = self.batch2(x)\n",
        "    x = self.ct3(x)\n",
        "\n",
        "    outputs = self.conv1(x)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwbmd83P4vGf"
      },
      "source": [
        "dummy_decoder = Decoder(latent_dim=128)\n",
        "results = dummy_decoder(dummy_result)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAMJ9brt7o7b"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "original = True\n",
        "for i in range(10):\n",
        "  plt.subplot(10,2,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  if original:\n",
        "    plt.imshow(np.reshape(train_images[i], newshape=(28, 28)))\n",
        "    original = False\n",
        "    i -= 1\n",
        "  else:\n",
        "    plt.imshow(np.reshape(results[i], newshape=(28, 28)))\n",
        "    original = True\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UssEoYVWOpte"
      },
      "source": [
        "## 4) Autoencoder Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgFRYpQ1km3"
      },
      "source": [
        "class Autoencoder(tf.keras.models.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = Encoder(latent_dim=latent_dim)\n",
        "    self.decoder = Decoder(latent_dim=latent_dim)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.encoder(x)\n",
        "    outputs = self.decoder(x)\n",
        "    return outputs"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNAKvHl7-hYi"
      },
      "source": [
        "dummy_autoencoder = Autoencoder(latent_dim=128)\n",
        "dummy_autoencoder(np.reshape(train_images[0], newshape=(1, 28, 28, 1))).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv-iKZVrjP_W"
      },
      "source": [
        "## 5) Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6czjL55-5Lm"
      },
      "source": [
        "'''\n",
        "  CALLBACKS:\n",
        "  These are functions that are called once a certain amount of epochs end. These come very handful to deal with overfitting\n",
        "'''\n",
        "\n",
        "# Lets load an extension that helps us to visualize the performance of our model\n",
        "%load_ext tensorboard\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/model/', histogram_freq=1)\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('logs/model/', monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_freq='epoch')\n",
        "earlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9NmOn_vecR3"
      },
      "source": [
        "## 6) Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17v9Qk4xcIPi"
      },
      "source": [
        "# Lets build the model. NOTE: this is the construction of the architecture of the model!\n",
        "autoencoder = Autoencoder(latent_dim=128)\n",
        "\n",
        "# Now lets compile the model. NOTE: These are the finishing touches before having a fully functional model\n",
        "autoencoder.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='adam', metrics=['mse'])\n",
        "\n",
        "# Before training, lets reshape our training date\n",
        "train_images = np.reshape(\n",
        "  train_images,\n",
        "  newshape=(train_images.shape[0], train_images.shape[1], train_images.shape[2], 1)\n",
        ")\n",
        "\n",
        "\n",
        "# Now lets train the model!\n",
        "autoencoder.fit(train_images,\n",
        "          train_images,\n",
        "          epochs=100,\n",
        "          batch_size = 128,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard_callback, checkpoint_callback, earlystopping_callback]\n",
        "        )\n",
        "\n",
        "# Lets evaluate our model\n",
        "#model.evaluate(x=test_images, y=test_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhQNj6_TBF1h"
      },
      "source": [
        "# Lets visualize\n",
        "%tensorboard --logdir \"logs/model/\" --port=8008"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STx8FeovBuTB"
      },
      "source": [
        "## 7) Lets watch the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chHuh1dpo6VD"
      },
      "source": [
        "# Lets reshape test images too!\n",
        "test_images = np.reshape(\n",
        "  test_images,\n",
        "  newshape=(test_images.shape[0], test_images.shape[1], test_images.shape[2], 1)\n",
        ")\n",
        "\n",
        "#test_images.shape\n",
        "index = 100\n",
        "total_imgs = 20\n",
        "subset_test_images = test_images[index: index + total_imgs]\n",
        "results = autoencoder.predict(\n",
        "    np.reshape(subset_test_images, newshape=(total_imgs, 28, 28, 1))\n",
        ")"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzWlzD4xPgRS"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i in range(4):\n",
        "  plt.subplot(10,2,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(np.reshape(subset_test_images[i], newshape=(28, 28)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjui8dI_RkBg"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i in range(4):\n",
        "  plt.subplot(10,2,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(np.reshape(results[i], newshape=(28, 28)))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}